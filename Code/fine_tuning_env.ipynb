{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-17T21:05:35.016276Z",
     "start_time": "2024-06-17T21:05:29.587230Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T21:35:58.209819Z",
     "start_time": "2024-06-17T21:35:57.315633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = \"../../Data/development_scenes_npy/development_scenes/\"\n",
    "data = []\n",
    "data_csv = pd.read_csv(\"../../Data/development_scenes_npy/development_scene_annotations.csv\")\n",
    "for filename in data_csv['filename']:\n",
    "    data.append(np.load(os.path.join(data_path, filename + \".npy\")))"
   ],
   "id": "10f97206c6c22cec",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T08:34:02.443811Z",
     "start_time": "2024-06-18T08:34:00.251192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = np.load(\"../../Data/development.npy\")\n",
    "data_csv = pd.read_csv(\"../../Data/metadata/development.csv\")\n",
    "idx_to_feature_name = pd.read_csv(\"../../Data/metadata/idx_to_feature_name.csv\")"
   ],
   "id": "139f52b2b0303ee9",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T08:52:41.450991Z",
     "start_time": "2024-06-18T08:52:41.408970Z"
    }
   },
   "cell_type": "code",
   "source": "data_no_other = data[:40834, :, :]",
   "id": "7b5f1d074fdfb379",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:00:42.898068Z",
     "start_time": "2024-06-18T09:00:41.515949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_csv_no_other = data_csv[:40834]\n",
    "fine_tune_words = ['Alarm', 'Fernseher', 'Heizung', 'Licht', 'LÃ¼ftung', 'Ofen', 'Radio', 'Staubsauger', 'an', 'aus']\n",
    "data_csv_fine_tune_indices = np.where(data_csv_no_other['word'].isin(fine_tune_words))[0].tolist()\n",
    "data_csv_no_other = np.array(data_csv_no_other)\n",
    "data_csv_fine_tune = [data_csv_no_other[i].tolist() for i in data_csv_fine_tune_indices]\n",
    "data_csv_fine_tune = np.array(data_csv_fine_tune)\n",
    "data_fine_tune = data_no_other[data_csv_fine_tune_indices]\n"
   ],
   "id": "c714e588f4abedf6",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T08:58:10.261455Z",
     "start_time": "2024-06-18T08:58:10.251257Z"
    }
   },
   "cell_type": "code",
   "source": "data_csv_fine_tune = data_csv_fine_tune.tolist()",
   "id": "267ce4ac15e5849",
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:00:46.478817Z",
     "start_time": "2024-06-18T09:00:46.471477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "speakers = np.unique(data_csv_fine_tune[:, 2])\n",
    "speakers = speakers.tolist()\n",
    "len(speakers)"
   ],
   "id": "5f900014333c3550",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:00:27.912975Z",
     "start_time": "2024-06-18T09:00:27.905641Z"
    }
   },
   "cell_type": "code",
   "source": "data_csv_fine_tune[:, 2]",
   "id": "99e9471b3e7e7c73",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '1', '1', ..., '89', '89', '89'], dtype='<U26')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:05:47.755455Z",
     "start_time": "2024-06-18T09:05:45.279210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "speakers_train = speakers[:137] \n",
    "speakers_valid = speakers[137:]\n",
    "\n",
    "train_indices = np.where(np.isin(data_csv_fine_tune[:, 2], speakers_train))[0].tolist()\n",
    "valid_indices = np.where(np.isin(data_csv_fine_tune[:, 2], speakers_valid))[0].tolist()\n",
    "\n",
    "data_train = data_fine_tune[train_indices]\n",
    "data_valid = data_fine_tune[valid_indices]\n",
    "\n",
    "labels_train = data_csv_fine_tune[:, 3][train_indices].tolist()\n",
    "labels_valid = data_csv_fine_tune[:, 3][valid_indices].tolist()\n",
    "\n",
    "labels = np.unique(data_csv_fine_tune[:, 3]).tolist()\n",
    "\n",
    "y = {}\n",
    "i = 0\n",
    "for label in labels:\n",
    "    y[label] = i\n",
    "    i += 1\n",
    "\n",
    "labels_train_num = []\n",
    "labels_valid_num = []\n",
    "\n",
    "for label in labels_train:\n",
    "    labels_train_num.append(y[label])\n",
    "for label in labels_valid:\n",
    "    labels_valid_num.append(y[label])"
   ],
   "id": "437cce488e6a2bb8",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:15:00.653750Z",
     "start_time": "2024-06-18T09:15:00.652354Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6ced1ddfb508daf2",
   "outputs": [],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:11:55.738140Z",
     "start_time": "2024-06-18T09:11:55.735962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(data_train), len(data_valid), len(labels_train_num), len(labels_valid_num))\n",
    "print(data_train.shape, data_valid.shape)"
   ],
   "id": "130aa55c3552c19b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16227 4192 16227 4192\n",
      "(16227, 175, 44) (4192, 175, 44)\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_tensor_train = torch.tensor(data_train, dtype=torch.float32)\n",
    "y_tensor_train = torch.tensor(labels_train_num, dtype=torch.long)\n",
    "X_tensor_valid = torch.tensor(data_valid, dtype=torch.float32)\n",
    "y_tensor_valid = torch.tensor(labels_valid_num, dtype=torch.long)"
   ],
   "id": "2e144e66648751d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]"
   ],
   "id": "6162e0fef491c000"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from model_architectures import EnhancedAudioCNN",
   "id": "59bf86292e13785c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:10:52.138026Z",
     "start_time": "2024-06-18T09:10:52.075014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = EnhancedAudioCNN()\n",
    "use_mps = torch.backends.mps.is_available()\n",
    "device = torch.device(\"mps\" if use_mps else \"cpu\")\n",
    "checkpoint = torch.load('data_leakage_fixed.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "dataset_train = CustomDataset(X_tensor_train, y_tensor_train)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=64, shuffle=True, drop_last=True)\n",
    "\n",
    "dataset_valid = CustomDataset(X_tensor_valid, y_tensor_valid)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=64, shuffle=False, drop_last=True)\n",
    "\n",
    "\n",
    "model.to(device)"
   ],
   "id": "5478913cc3e11a93",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnhancedAudioCNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=1280, out_features=32, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  (fc2): Linear(in_features=32, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:11:07.161622Z",
     "start_time": "2024-06-18T09:11:07.030260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example training loop\n",
    "num_epochs = 50\n",
    "#total_iterations = num_epochs * (len(dataloader_train) + len(dataloader_valid))\n",
    "#progress_bar = tqdm(total=total_iterations, desc='Training and Evaluation')\n",
    "\n",
    "losses_train = []\n",
    "losses_valid = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for features, labels in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        features = features.unsqueeze(1)\n",
    "        inputs = features.to(device)\n",
    "        targets = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    losses_train.append(loss.item())\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for features, labels in dataloader_valid:\n",
    "            inputs = features.to(device)\n",
    "            inputs = inputs.unsqueeze(1)\n",
    "            targets = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "        losses_valid.append(loss.item())\n",
    "    if (losses_train[-1] + losses_valid[-1])/2 < 0.1:\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, f'model_epoch_{epoch}.pth')\n",
    "    #progress_bar.update(2)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Training loss: {losses_train[-1]}, Validation loss: {losses_valid[-1]}')"
   ],
   "id": "319598e9e017441",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 845 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[117], line 11\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[1;32m     10\u001B[0m     model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m---> 11\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m features, labels \u001B[38;5;129;01min\u001B[39;00m dataloader_train:\n\u001B[1;32m     12\u001B[0m         optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     13\u001B[0m         features \u001B[38;5;241m=\u001B[39m features\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    672\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    673\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 674\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    675\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    676\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Cell \u001B[0;32mIn[35], line 10\u001B[0m, in \u001B[0;36mCustomDataset.__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index):\n\u001B[0;32m---> 10\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures[index], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels[index]\n",
      "\u001B[0;31mIndexError\u001B[0m: index 845 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T08:34:52.063979Z",
     "start_time": "2024-06-18T08:34:52.059399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def segment_features(features, segment_frames=44, hop_frames=1):\n",
    "    # Number of feature frames in the file\n",
    "    num_frames = features.shape[1]\n",
    "    \n",
    "    # Calculate the number of segments we can extract\n",
    "    num_segments = 1 + (num_frames - segment_frames) // hop_frames\n",
    "    \n",
    "    # Prepare an array to store segments\n",
    "    segments = []\n",
    "    \n",
    "    # Extract segments using a sliding window\n",
    "    for i in range(num_segments):\n",
    "        start_frame = i * hop_frames\n",
    "        end_frame = start_frame + segment_frames\n",
    "        segment = features[:, start_frame:end_frame]\n",
    "        segments.append(segment)\n",
    "        \n",
    "    return np.array(segments)"
   ],
   "id": "6410048bc6af991b",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T08:34:43.419585Z",
     "start_time": "2024-06-18T08:34:41.958211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "frame_rate = 39\n",
    "commands = []\n",
    "labels = []\n",
    "max_length = 0\n",
    "min_end = 10000000\n",
    "def extract_commands(frame_rate, start, max_length, snippet):\n",
    "    start_frame = int(start * frame_rate)\n",
    "    if snippet.shape[1] < start_frame + max_length:\n",
    "        padding = np.zeros((snippet.shape[0], start_frame + max_length - snippet.shape[1]))\n",
    "        snippet = np.hstack((snippet, padding))\n",
    "    return snippet[:, start_frame:start_frame + max_length]\n",
    "\n",
    "for i in range(len(data)):\n",
    "    start = data_csv['start'][i] * frame_rate\n",
    "    end = data_csv['end'][i] * frame_rate\n",
    "    max_length = max(end - start, max_length)\n",
    "    min_end = min(end, min_end)\n",
    "max_length = int(max_length) + 1\n",
    "\n",
    "    \n",
    "for i in range(len(data)):\n",
    "    start = data_csv['start'][i]\n",
    "    snippet = data[i]\n",
    "    commands.append(extract_commands(frame_rate, start, max_length, snippet))\n",
    "    labels.append(data_csv['command'][i])"
   ],
   "id": "1be0a32744e10424",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'start'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3801\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'start'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[60], line 14\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m snippet[:, start_frame:start_frame \u001B[38;5;241m+\u001B[39m max_length]\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(data)):\n\u001B[0;32m---> 14\u001B[0m     start \u001B[38;5;241m=\u001B[39m data_csv[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstart\u001B[39m\u001B[38;5;124m'\u001B[39m][i] \u001B[38;5;241m*\u001B[39m frame_rate\n\u001B[1;32m     15\u001B[0m     end \u001B[38;5;241m=\u001B[39m data_csv[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mend\u001B[39m\u001B[38;5;124m'\u001B[39m][i] \u001B[38;5;241m*\u001B[39m frame_rate\n\u001B[1;32m     16\u001B[0m     max_length \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(end \u001B[38;5;241m-\u001B[39m start, max_length)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3807\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3807\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mget_loc(key)\n\u001B[1;32m   3808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3809\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3804\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3804\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3808\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3809\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'start'"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T21:48:49.605725Z",
     "start_time": "2024-06-17T21:48:44.091131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "command_segments = []\n",
    "for i in range(len(commands)):\n",
    "    command_segments.append(segment_features(commands[i]))"
   ],
   "id": "85c85dff01c59c34",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T21:48:56.317180Z",
     "start_time": "2024-06-17T21:48:56.276349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(len(command_segments)):\n",
    "    if command_segments[i+1].shape != command_segments[i].shape:\n",
    "        print(command_segments[i].shape)"
   ],
   "id": "e6e3140a0939f196",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(command_segments)):\n\u001B[0;32m----> 2\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m command_segments[i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m!=\u001B[39m command_segments[i]\u001B[38;5;241m.\u001B[39mshape:\n\u001B[1;32m      3\u001B[0m         \u001B[38;5;28mprint\u001B[39m(command_segments[i]\u001B[38;5;241m.\u001B[39mshape)\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T21:49:04.872511Z",
     "start_time": "2024-06-17T21:48:59.694558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "commands_train = np.array(command_segments[:952])\n",
    "commands_val = np.array(command_segments[952:])\n",
    "\n",
    "labels_train = labels[:952]\n",
    "labels_val = labels[952:]"
   ],
   "id": "1b43c1d866a0e324",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T21:49:17.303576Z",
     "start_time": "2024-06-17T21:49:17.281089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "i = 20\n",
    "y = {}\n",
    "labels_train_num = []\n",
    "labels_val_num = []\n",
    "\n",
    "for label in np.unique(labels).tolist():\n",
    "    y[label] = i\n",
    "    i += 1\n",
    "    \n",
    "for label in labels_train:\n",
    "    labels_train_num.append(y[label])\n",
    "for label in labels_val:\n",
    "    labels_val_num.append(y[label])\n",
    "\n",
    "labels_train_num = np.array(labels_train_num)\n",
    "labels_val_num = np.array(labels_val_num)"
   ],
   "id": "ec5d412832ba5220",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T21:49:24.025564Z",
     "start_time": "2024-06-17T21:49:20.370564Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "74fd74f5339993ab",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T21:51:55.233389Z",
     "start_time": "2024-06-17T21:51:55.226609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]"
   ],
   "id": "ec6648f8bf72580b",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T21:52:45.318602Z",
     "start_time": "2024-06-17T21:52:45.308197Z"
    }
   },
   "cell_type": "code",
   "source": "from model_architectures import EnhancedAudioCNN",
   "id": "8aaa2e45677e8613",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T22:09:25.589346Z",
     "start_time": "2024-06-17T22:09:13.556081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "use_mps = torch.backends.mps.is_available()\n",
    "device = torch.device(\"mps\" if use_mps else \"cpu\")\n",
    "\n",
    "pretrained_model = EnhancedAudioCNN(num_classes=20)\n",
    "checkpoint = torch.load (\"model_epoch_17.pth\", map_location=device)\n",
    "pretrained_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "model = EnhancedAudioCNN(num_classes=37)\n",
    "\n",
    "model_dict = model.state_dict()\n",
    "pretrained_dict = pretrained_model.state_dict()\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and \"fc2\" not in k}\n",
    "model_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_dict)\n",
    "\n",
    "# Initialize the weights of the new output layer\n",
    "nn.init.xavier_uniform_(model.fc2.weight)\n",
    "nn.init.zeros_(model.fc2.bias)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "X_tensor_train = torch.tensor(commands_train, dtype=torch.float32).to(device)\n",
    "y_tensor_train = torch.tensor([labels_train_num], dtype=torch.long).to(device)\n",
    "X_tensor_valid = torch.tensor(commands_val, dtype=torch.float32).to(device)\n",
    "y_tensor_valid = torch.tensor([labels_val_num], dtype=torch.long).to(device)\n",
    "\n",
    "model.to(device)"
   ],
   "id": "9075de0508f96d9d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnhancedAudioCNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=1280, out_features=32, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  (fc2): Linear(in_features=32, out_features=37, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T22:13:56.156536Z",
     "start_time": "2024-06-17T22:13:56.106446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example training loop\n",
    "num_epochs = 20\n",
    "#total_iterations = num_epochs * (len(dataloader_train) + len(dataloader_valid))\n",
    "#progress_bar = tqdm(total=total_iterations, desc='Training and Evaluation')\n",
    "\n",
    "losses_train = []\n",
    "losses_valid = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for features, labels in zip(X_tensor_train, y_tensor_train):\n",
    "        optimizer.zero_grad()\n",
    "        print(features[0].shape)\n",
    "        inputs = features.unsqueeze(1).to(device)\n",
    "        targets = labels.unsqueeze(1).to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    losses_train.append(loss.item())\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for features, labels in zip(X_tensor_valid, y_tensor_valid):\n",
    "            inputs = features.unsqueeze(1).to(device)\n",
    "            targets = labels.unsqueeze(1).to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "        losses_valid.append(loss.item())\n",
    "    if losses_train[-1] < 0.3 and losses_valid[-1] < 0.3:\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, f'model_epoch_{epoch}.pth')\n",
    "    #progress_bar.update(2)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Training loss: {losses_train[-1]}, Validation loss: {losses_valid[-1]}')"
   ],
   "id": "4d532a81b3f55fd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([175, 44])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (66) to match target batch_size (952).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[57], line 17\u001B[0m\n\u001B[1;32m     15\u001B[0m targets \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     16\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(inputs)\n\u001B[0;32m---> 17\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, targets)\n\u001B[1;32m     18\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     19\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/loss.py:1179\u001B[0m, in \u001B[0;36mCrossEntropyLoss.forward\u001B[0;34m(self, input, target)\u001B[0m\n\u001B[1;32m   1178\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m-> 1179\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mcross_entropy(\u001B[38;5;28minput\u001B[39m, target, weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight,\n\u001B[1;32m   1180\u001B[0m                            ignore_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mignore_index, reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreduction,\n\u001B[1;32m   1181\u001B[0m                            label_smoothing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabel_smoothing)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:3053\u001B[0m, in \u001B[0;36mcross_entropy\u001B[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[1;32m   3051\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3052\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[0;32m-> 3053\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_nn\u001B[38;5;241m.\u001B[39mcross_entropy_loss(\u001B[38;5;28minput\u001B[39m, target, weight, _Reduction\u001B[38;5;241m.\u001B[39mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001B[0;31mValueError\u001B[0m: Expected input batch_size (66) to match target batch_size (952)."
     ]
    }
   ],
   "execution_count": 57
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
