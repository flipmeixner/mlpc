{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-19T07:34:09.258947Z",
     "start_time": "2024-06-19T07:34:09.252405Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from utils import segment_features, predictions\n",
    "from model_architectures import EnhancedAudioCNN"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T07:34:10.378309Z",
     "start_time": "2024-06-19T07:34:09.263619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = \"../../Data/development_scenes_npy/development_scenes/\"\n",
    "data_csv = pd.read_csv(\"../../Data/development_scenes_npy/development_scene_annotations.csv\")\n",
    "data = []\n",
    "filenames = []\n",
    "for filename in data_csv['filename']:\n",
    "    data.append((np.load(os.path.join(data_path, filename + \".npy\"))))\n",
    "    filenames.append(filename)"
   ],
   "id": "c7ad6e72cc4884b5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T07:34:10.409509Z",
     "start_time": "2024-06-19T07:34:10.387414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reshaped_data = []\n",
    "for file in data:\n",
    "    reshaped_data.append(np.expand_dims(file, axis=0))"
   ],
   "id": "4bd375ba8479a18",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T07:34:10.412865Z",
     "start_time": "2024-06-19T07:34:10.410241Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "505ba1b123392d08",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T07:34:10.420682Z",
     "start_time": "2024-06-19T07:34:10.414646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_model(model_path, device='cpu'):\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model = EnhancedAudioCNN()\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model"
   ],
   "id": "aeecd3a4ecdbd9ac",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T07:34:10.428045Z",
     "start_time": "2024-06-19T07:34:10.421651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def inference_results(sample, model_path, device):\n",
    "    # Load the model\n",
    "    model = load_model(model_path, device=device)\n",
    "    results = []\n",
    "    sample = segment_features(sample)\n",
    "    sample = torch.tensor(sample, dtype=torch.float32).to(device)\n",
    "    sample = sample.unsqueeze(1)\n",
    "    for segment_tensor in sample:\n",
    "        # Each tensor in segments is (1, feature_dim, segment_frames), which should match the expected input shape of your model\n",
    "        segment_tensor = segment_tensor.unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(segment_tensor)\n",
    "            results.append(torch.softmax(output, dim=1).detach().cpu().numpy())\n",
    "    return results"
   ],
   "id": "d72d360236a9d288",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T07:34:10.484532Z",
     "start_time": "2024-06-19T07:34:10.429084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "use_mps = torch.backends.mps.is_available()\n",
    "device = torch.device(\"mps\" if use_mps else \"cpu\")"
   ],
   "id": "aec03e4aae804861",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-19T07:34:10.485328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = \"model_epoch_47.pth\"\n",
    "final_predictions = {'filename': [],\n",
    "                     'command': [],\n",
    "                     'timestamp': []\n",
    "                     }\n",
    "i = 0\n",
    "\n",
    "for sample, file in zip(reshaped_data, filenames):\n",
    "    result = inference_results(sample[0], model_path, device)\n",
    "    final_prediction = (predictions(result))\n",
    "    for pred in final_prediction:\n",
    "        final_predictions['filename'].append(file)\n",
    "        final_predictions['command'].append(pred[0])\n",
    "        final_predictions['timestamp'].append(pred[1]/39)\n",
    "    i += 1\n",
    "    print(i, \"/\", len(filenames))"
   ],
   "id": "bf650780342e0df2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 1190\n",
      "2 / 1190\n",
      "3 / 1190\n",
      "4 / 1190\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(final_predictions)\n",
    "csv_path = 'predictions.csv'\n",
    "df.to_csv(csv_path, index=False)"
   ],
   "id": "573851e8ca87dcfd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "SmartVoiceControl has also released a specification of the costs associated with correct and\n",
    "incorrect predictions. This new evaluation metric is better aligned with the actual goals of the\n",
    "application and deviates significantly from the purely classification-based evaluation used in\n",
    "the previous assignment. The proposed cost function distinguishes between four types of\n",
    "events:\n",
    "\n",
    "- True Positives: A speech command was issued and correctly detected by the system.\n",
    "A detection is considered correct if the predicted timestamp is within the\n",
    "annotation’s onset and offset. The associated cost is -1.\n",
    "\n",
    "- False Negatives: A speech command was issued, but the system did not detect a\n",
    "command. This is annoying but often a result of sloppy pronunciation; users will\n",
    "adjust their speech to the system over time. The associated cost is 0.5\n",
    "\n",
    "\n",
    "- False Positives: The system wrongfully detects a speech command. Depending on\n",
    "the command, the consequences of wrongful detections range from spooky and\n",
    "bothersome to potentially dangerous (luckily, there will be some additional\n",
    "safeguards to avoid the worst). The associated costs, therefore, depend on the\n",
    "wrongfully detected command:\n",
    " * {“Fernseher”, “Licht”, “Radio”, or “Staubsauger”} + {“an” or “aus”}: 2\n",
    " * {“Heizung” or “Lüftung”} + {“an” or “aus”}: 3\n",
    " * {“Ofen” or “Alarm” } + {“an” or “aus”}: 4\n",
    "\n",
    "- Cross-Triggers: Cross-Triggers are a special type of false positives. They occur when\n",
    "a user intends to interact with the system by issuing a speech command, but the\n",
    "system does not recognize the correct command. This lowers the perceived quality of\n",
    "the voice control system and leads to user frustration. However, Cross-Triggers are\n",
    "less expensive compared to general false positives, as the user receives feedback\n",
    "from the system and can manually intervene if the system makes a critical mistake\n",
    "(e.g., detecting \"Ofen an\", or \"Alarm aus\" instead of the intended speech command).\n",
    "In general, Cross-Triggers result in a cost of 1. Luckily, not all Cross-Triggers are\n",
    "that expensive; the system automatically corrects incorrect action keywords. For\n",
    "example, if the radio (“Radio”) is on and the user issues “Radio aus” (i.e., radio off),\n",
    "but the system detects “Radio an” (i.e., radio on), the system will automatically\n",
    "correct the classification to “Radio aus” (i.e., radio off). The cost for incorrect action\n",
    "keywords with correct device keywords is, therefore, 0.1."
   ],
   "id": "f028ff04fca56f8"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c71a34b3e6b598ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f138d59cd33d5b83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "dea1161a86342210",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
