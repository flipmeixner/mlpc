{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-19T09:49:26.693162Z",
     "start_time": "2024-06-19T09:49:23.214524Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from utils import segment_features, predictions\n",
    "from model_architectures import EnhancedAudioCNN"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:52:52.774435Z",
     "start_time": "2024-06-19T09:52:51.522946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = \"../../Data/development_scenes_npy/development_scenes/\"\n",
    "data_csv = pd.read_csv(\"../../Data/development_scenes_npy/development_scene_annotations.csv\")\n",
    "data = []\n",
    "filenames = []\n",
    "for filename in data_csv['filename']:\n",
    "    data.append((np.load(os.path.join(data_path, filename + \".npy\"))))\n",
    "    filenames.append(filename)"
   ],
   "id": "c7ad6e72cc4884b5",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:52:53.966807Z",
     "start_time": "2024-06-19T09:52:53.962444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reshaped_data = []\n",
    "for file in data:\n",
    "    reshaped_data.append(np.expand_dims(file, axis=0))"
   ],
   "id": "4bd375ba8479a18",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T07:34:10.412865Z",
     "start_time": "2024-06-19T07:34:10.410241Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "505ba1b123392d08",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:52:56.395467Z",
     "start_time": "2024-06-19T09:52:56.386941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_model(model_path, device='cpu'):\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model = EnhancedAudioCNN()\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model"
   ],
   "id": "aeecd3a4ecdbd9ac",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:53:08.969025Z",
     "start_time": "2024-06-19T09:53:08.962167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def inference_results(sample, model_path, device):\n",
    "    # Load the model\n",
    "    model = load_model(model_path, device=device)\n",
    "    results = []\n",
    "    sample = segment_features(sample)\n",
    "    sample = torch.tensor(sample, dtype=torch.float32).to(device)\n",
    "    sample = sample.unsqueeze(1)\n",
    "    for segment_tensor in sample:\n",
    "        # Each tensor in segments is (1, feature_dim, segment_frames), which should match the expected input shape of your model\n",
    "        segment_tensor = segment_tensor.unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(segment_tensor)\n",
    "            results.append(torch.softmax(output, dim=1).detach().cpu().numpy())\n",
    "    return results"
   ],
   "id": "d72d360236a9d288",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:53:10.971634Z",
     "start_time": "2024-06-19T09:53:10.898393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "use_mps = torch.backends.mps.is_available()\n",
    "device = torch.device(\"mps\" if use_mps else \"cpu\")"
   ],
   "id": "aec03e4aae804861",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:21:15.374647Z",
     "start_time": "2024-06-19T09:21:15.366430Z"
    }
   },
   "cell_type": "code",
   "source": "len(filenames)",
   "id": "11ca66ffd8e521ee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1190"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:35:42.904591Z",
     "start_time": "2024-06-19T14:35:38.615762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = \"model_epoch_47.pth\"\n",
    "final_predictions = {'filename': [],\n",
    "                     'command': [],\n",
    "                     'timestamp': []\n",
    "                     }\n",
    "i = 0\n",
    "final_pred_last = []\n",
    "for sample, file in zip(reshaped_data, filenames):\n",
    "    print(sample.shape)\n",
    "    result = inference_results(sample[0], model_path, device)\n",
    "    final_prediction = (predictions(result))\n",
    "    if final_prediction == final_pred_last:\n",
    "        continue\n",
    "    for pred in final_prediction:\n",
    "        final_predictions['filename'].append(file)\n",
    "        final_predictions['command'].append(pred[0])\n",
    "        final_predictions['timestamp'].append(pred[1]/39 + 0.5)\n",
    "        i += 1\n",
    "        print(i, \"/\", len(filenames))\n",
    "    final_pred_last = final_prediction\n",
    "    "
   ],
   "id": "bf650780342e0df2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 175, 581)\n",
      "1 / 1190\n",
      "(1, 175, 1109)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[33], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sample, file \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(reshaped_data, filenames):\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28mprint\u001B[39m(sample\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m---> 10\u001B[0m     result \u001B[38;5;241m=\u001B[39m inference_results(sample[\u001B[38;5;241m0\u001B[39m], model_path, device)\n\u001B[1;32m     11\u001B[0m     final_prediction \u001B[38;5;241m=\u001B[39m (predictions(result))\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m final_prediction \u001B[38;5;241m==\u001B[39m final_pred_last:\n",
      "Cell \u001B[0;32mIn[13], line 13\u001B[0m, in \u001B[0;36minference_results\u001B[0;34m(sample, model_path, device)\u001B[0m\n\u001B[1;32m     10\u001B[0m     segment_tensor \u001B[38;5;241m=\u001B[39m segment_tensor\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 13\u001B[0m         output \u001B[38;5;241m=\u001B[39m model(segment_tensor)\n\u001B[1;32m     14\u001B[0m         results\u001B[38;5;241m.\u001B[39mappend(torch\u001B[38;5;241m.\u001B[39msoftmax(output, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m results\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/CloudStorage/OneDrive-Personal/Philip/_Studium/JKU/SS2024/MLPC/mlpc/Code/model_architectures.py:26\u001B[0m, in \u001B[0;36mEnhancedAudioCNN.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     24\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn2(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(x))))\n\u001B[1;32m     25\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout1(x)\n\u001B[0;32m---> 26\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn3(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv3(x))))\n\u001B[1;32m     27\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn4(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv4(x))))\n\u001B[1;32m     28\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout2(x)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_conv_forward(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    453\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    454\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    455\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 456\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(\u001B[38;5;28minput\u001B[39m, weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    457\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:49:12.767728Z",
     "start_time": "2024-06-19T10:49:12.759436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(final_predictions)\n",
    "df"
   ],
   "id": "7acb6b647ce70f4e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        filename      command  timestamp\n",
       "0         2_speech_true_Ofen_aus  Heizung aus   6.141026\n",
       "1         4_speech_true_Alarm_an     Alarm an  15.243590\n",
       "2    19_speech_false_Lüftung_aus  Lüftung aus   8.884615\n",
       "3     22_speech_false_Heizung_an   Heizung an   7.217949\n",
       "4        24_speech_true_Licht_an     Licht an  13.243590\n",
       "..                           ...          ...        ...\n",
       "976  2019_speech_true_Heizung_an   Heizung an  16.602564\n",
       "977  2020_speech_true_Lüftung_an   Lüftung an  13.679487\n",
       "978   2021_speech_false_Radio_an     Radio an  11.166667\n",
       "979    2022_speech_true_Alarm_an     Alarm an  21.166667\n",
       "980    2023_speech_true_Licht_an     Licht an   7.833333\n",
       "\n",
       "[981 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>command</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2_speech_true_Ofen_aus</td>\n",
       "      <td>Heizung aus</td>\n",
       "      <td>6.141026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4_speech_true_Alarm_an</td>\n",
       "      <td>Alarm an</td>\n",
       "      <td>15.243590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19_speech_false_Lüftung_aus</td>\n",
       "      <td>Lüftung aus</td>\n",
       "      <td>8.884615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22_speech_false_Heizung_an</td>\n",
       "      <td>Heizung an</td>\n",
       "      <td>7.217949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24_speech_true_Licht_an</td>\n",
       "      <td>Licht an</td>\n",
       "      <td>13.243590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>2019_speech_true_Heizung_an</td>\n",
       "      <td>Heizung an</td>\n",
       "      <td>16.602564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>2020_speech_true_Lüftung_an</td>\n",
       "      <td>Lüftung an</td>\n",
       "      <td>13.679487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>2021_speech_false_Radio_an</td>\n",
       "      <td>Radio an</td>\n",
       "      <td>11.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>2022_speech_true_Alarm_an</td>\n",
       "      <td>Alarm an</td>\n",
       "      <td>21.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>2023_speech_true_Licht_an</td>\n",
       "      <td>Licht an</td>\n",
       "      <td>7.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>981 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T13:37:24.197903Z",
     "start_time": "2024-06-19T13:37:24.192104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_1 = pd.DataFrame(final_predictions)\n",
    "df_1.to_csv(\"data_leakage_fixed.csv\", index=False)"
   ],
   "id": "d157c169de74162",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:50:01.427040Z",
     "start_time": "2024-06-19T10:50:01.410348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(final_predictions)\n",
    "csv_path = 'predictions.csv'\n",
    "df.to_csv(csv_path, index=False)"
   ],
   "id": "573851e8ca87dcfd",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "SmartVoiceControl has also released a specification of the costs associated with correct and\n",
    "incorrect predictions. This new evaluation metric is better aligned with the actual goals of the\n",
    "application and deviates significantly from the purely classification-based evaluation used in\n",
    "the previous assignment. The proposed cost function distinguishes between four types of\n",
    "events:\n",
    "\n",
    "- True Positives: A speech command was issued and correctly detected by the system.\n",
    "A detection is considered correct if the predicted timestamp is within the\n",
    "annotation’s onset and offset. The associated cost is -1.\n",
    "\n",
    "- False Negatives: A speech command was issued, but the system did not detect a\n",
    "command. This is annoying but often a result of sloppy pronunciation; users will\n",
    "adjust their speech to the system over time. The associated cost is 0.5\n",
    "\n",
    "\n",
    "- False Positives: The system wrongfully detects a speech command. Depending on\n",
    "the command, the consequences of wrongful detections range from spooky and\n",
    "bothersome to potentially dangerous (luckily, there will be some additional\n",
    "safeguards to avoid the worst). The associated costs, therefore, depend on the\n",
    "wrongfully detected command:\n",
    " * {“Fernseher”, “Licht”, “Radio”, or “Staubsauger”} + {“an” or “aus”}: 2\n",
    " * {“Heizung” or “Lüftung”} + {“an” or “aus”}: 3\n",
    " * {“Ofen” or “Alarm” } + {“an” or “aus”}: 4\n",
    "\n",
    "- Cross-Triggers: Cross-Triggers are a special type of false positives. They occur when\n",
    "a user intends to interact with the system by issuing a speech command, but the\n",
    "system does not recognize the correct command. This lowers the perceived quality of\n",
    "the voice control system and leads to user frustration. However, Cross-Triggers are\n",
    "less expensive compared to general false positives, as the user receives feedback\n",
    "from the system and can manually intervene if the system makes a critical mistake\n",
    "(e.g., detecting \"Ofen an\", or \"Alarm aus\" instead of the intended speech command).\n",
    "In general, Cross-Triggers result in a cost of 1. Luckily, not all Cross-Triggers are\n",
    "that expensive; the system automatically corrects incorrect action keywords. For\n",
    "example, if the radio (“Radio”) is on and the user issues “Radio aus” (i.e., radio off),\n",
    "but the system detects “Radio an” (i.e., radio on), the system will automatically\n",
    "correct the classification to “Radio aus” (i.e., radio off). The cost for incorrect action\n",
    "keywords with correct device keywords is, therefore, 0.1."
   ],
   "id": "f028ff04fca56f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
